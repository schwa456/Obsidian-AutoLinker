# .env 파일
# LLM 서버 주소 (Ollama는 보통 11434, vLLM은 8000)
LLM_BASE_URL=http://localhost:11434/v1
LLM_API_KEY=ollama

# 사용할 모델명 (실제 로컬에 받아져 있는 모델명과 일치해야 함)
# 예: llama3, mistral, gemma2, eeve-korean 등
LLM_MODEL_NAME=llama3

# 백엔드 서버 설정
SERVER_HOST=127.0.0.1
SERVER_PORT=5000